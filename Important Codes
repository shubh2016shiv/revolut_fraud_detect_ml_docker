########## TIMING EACH FUNCTION IN LAMBDA ##########

1. Define the timing decorator:

```python
import time

def timing_decorator(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        print(f"Function {func.__name__} started at {start_time}, ended at {end_time}, and took {elapsed_time:.2f} seconds to complete.")
        return result
    return wrapper
```

2. Use the decorator for the functions you want to measure:

```python
@timing_decorator
def example_function():
    # Some code here
    time.sleep(2)  # Just for demonstration purposes

@timing_decorator
def another_example_function():
    # Some code here
    time.sleep(1)  # Just for demonstration purposes
```

3. Call the functions:

```python
example_function()
another_example_function()
```

When you call the decorated functions, you'll get print statements indicating the start and end times, and the elapsed time for each function.

In a Lambda environment, instead of `print`, you might want to use `LOGGER.info()` or another logging method to send the timings to CloudWatch Logs or your preferred logging mechanism. Adjust the `print` statement in the `timing_decorator` accordingly.



######### Command to test the connection to  AWS from local computer #########  
aws sts get-caller-identity


######### Download the Model from S3 #########

def load_and_replace_model_from_s3(bucket_name, model_prefix, local_dir):
    print("DOWNLOADING LATEST TRAINED MODEL FROM S3 AND REPLACING THE OLD TRAINED MODEL")
    # Initialize the S3 client
    s3_client = boto3.client('s3')

    # List all objects in the S3 bucket with the specified prefix
    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=model_prefix)

    if 'Contents' not in response:
        print(f"No model files found in S3 with prefix '{model_prefix}'.")
        return None

    # Download all model files from S3 to the local directory
    for s3_object in response['Contents'][1:]:
        s3_key = s3_object['Key']
        local_path = os.path.join(local_dir, os.path.basename(s3_key))

        try:
            s3_client.download_file(bucket_name, s3_key, local_path)
            print(f"Downloaded: {s3_key}")
        except Exception as e:
            print(f"Failed to download {s3_key}: {e}")
            return None

    # Load the model using TensorFlow
    model = Convnet()
    model.load_weights(local_dir + '/tf_model_weights')

    return model
